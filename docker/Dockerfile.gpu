# --- docker/Dockerfile.gpu ---
FROM nvidia/cuda:11.8.0-runtime-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
ENV USE_GPU=True
ENV PYTHONPATH=/workspace
ENV FAISS_INDEX_PATH=/data/vector.index

WORKDIR /workspace

# System dependencies
RUN apt-get update --fix-missing && \
    apt-get install -y --no-install-recommends \
        git wget curl \
        python3 python3-pip \
        ffmpeg libsndfile1 libgl1 jq \
        ca-certificates && \
    curl -fsSL https://deb.nodesource.com/setup_lts.x | bash - && \
    apt-get install -y nodejs && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Python setup
COPY requirements-gpu.txt .
RUN python3 -m pip install --upgrade pip setuptools wheel && \
    pip install --no-cache-dir -r requirements-gpu.txt

# PyTorch with CUDA 11.8
RUN pip install torch==2.2.2 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Copy frontend dependencies separately for build caching
COPY frontend/package*.json ./frontend/
RUN cd frontend && npm ci && cd ..

# Copy code
COPY . .

# Build frontend
RUN cd frontend && npm run build && cd ..

# Build frontend
RUN cd frontend && npm ci && npm run build && cd ..

# Ensure FAISS index path exists
RUN mkdir -p /data

# Expose both ports
EXPOSE 8000 8080 3000

# Run FastAPI and Streamlit together
CMD ["bash", "-c", "uvicorn app.main_fastapi:app --host 0.0.0.0 --port 8000 & streamlit run app/main_streamlit.py --server.port=8080 --server.address=0.0.0.0 --server.enableCORS=false --server.enableXsrfProtection=false --server.headless=true & cd frontend && npm run preview -- --host 0.0.0.0 --port 3000"]
